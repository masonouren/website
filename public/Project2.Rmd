---
title: "Computational Biology Project 2"
author: "Mason Ouren"
date: "11/26/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)
```

# *Project 2: Modeling*


##### *For this project, I selected a dataset containing information about dementia patients. The variables in this dataset include patient identification, dementia status (binary; either demented or nondemented), gender (M/F), age, years of education (EDUC), socioeconomic status (SES), score from a minimal mental state exam (MMSE), estimated total intracranial volume (eTIV), normalized whole brain volume (nWBV), and the Atlas scaling factor (ASF) (this was not used much in the practical analysis). The variable referring to the patients' visits and the "Hand" variable were not informative (the same for every patient after tidying). Some variables, while coded numerically, are more categorical in nature (like SES), some are purely categorical (like gender and dementia status), and some are purely numeric (like normalized whole brain volume and estimated total intracranial volume). I chose this dataset because my grandmother passed away from dementia, and I was curious to see if I could create a model that effectively predicts dementia status and, if so, identify which variables are the most predictive of dementia. Intuitively, it would seem that age would be the most weighty factor in the presence of dementia, but I discovered that other variables actually carry more predictive weight--see the rest of the project to find out which ones!*


##### *Reading in the dementia dataset and tidying it up by removing repetitive rows, removing a column that has only zeros, making demented/nondemented binary numeric, and removing the column containing the demented/nondemented diagnosis (this is now encoded by 0 for "nondemented" and 1 for "demented" in the column labeled "Demented").*
```{R}
#Loading in some packages into the environment
library(tidyverse); library(dplyr)

#reading in the data table as a .csv
dementia_untidy <- read.csv("C:/Users/mason/OneDrive/SDS 348 Comp Bio/Dementia_Table.csv")

dementia <- dementia_untidy %>% filter(Visit == 1) %>% select(-MR.Delay) %>% mutate(Demented = recode(Group, "Nondemented" = 0, "Demented" = 1)) %>% select(-Group) %>% na.omit()
```
##### *Tidying the data table to make it easier to work with; eliminated repetitive rows, deleted non-informative column, created binary variable for demented/nondemented patients, and omitted NAs*


### *MANOVA*
```{R}
#MANOVA
man1<-manova(cbind(EDUC,nWBV)~Demented, data=dementia)
summary(man1)
```
##### *The MANOVA is showing significant values for both variables (years of education and normalized whole brain volume), meaning we will perform univariate ANOVAs to further examine the variance across these variables. Other variables were omitted for the following reasons: MMSE and CDR are dementia predictions that are not really measurements and therefore produce non-informative variance results; estimated total intracranial volume is not helpful to include since normalized whole brain volume is a better metric to use (since it's normalized); the other variables are categorical.*

```{R}
#Univariate ANOVAs
summary.aov(man1)
```
##### *The univariate ANOVAs show significant variance across both variables. Since the "Demented" response variable is binary, no t-tests are necessary (we know that any significance in variance must be between these two groups).*

```{R}
#1 MANOVA and 2 ANOVAs (3 tests total), so:

#Likelihood of Type 1 Error:
type1error <- 0.05*3
type1error
```
##### *The likelihood of a type 1 error is 15%.*

```{R}
#Bonferroni correction: alpha needs to be divided by 3
bonferroni <- 0.05/3
bonferroni #Adjusted alpha
```
##### *The bonferroni correction creates an alpha of 0.01666667. Variance of both variables remains significant even after the correction.*

```{R}
#For normality assumption: plot variables to observe normality
ggplot(dementia, aes(x = nWBV, y = EDUC)) +  geom_point(alpha = .5) + facet_wrap(~Demented) + ggtitle("Distribution of EDUC by nWBV in Demented and Nondemented Individuals")
```

##### *Since years of education is a discrete number, the graph forms lines (instead of circles) when trying to mimic the example from the iris dataset, so I removed the lines. Multivariate normality looks decent enough.*

```{R}
#For homogeneity of variance assumption: make covariance matrices
covmats<-dementia %>% select("Demented", "EDUC", "nWBV") %>% group_by(Demented) %>% do(covs=cov(.[2:3])) 
for(i in 1:2){print(covmats$covs[i])}
```
##### *The MANOVA assumes equal variances/covariances across all variables, but these tables show that this assumption is not met. As for other requirements for the MANOVA, there are more samples than variables and there are not many zeros or outliers.*


## *Ranodmization Test: PERMANOVA*

##### *Next, I perform a PERMANOVA as a randomization test to re-examine the MANOVA results while circumventing some of the hard-to-meet assumptions:*
```{R}
#RANDOMIZATION TEST (PERMANOVA)
#install.packages("vegan")
library(vegan)

dists<-dementia%>%select(EDUC, nWBV)%>%dist() #generating vector of distances
```


##### *Null Hypothesis: There is no significant mean difference across any of the variables (education and normalized whole brain volume).*

##### *Alternative Hypotheis: There is a significant mean difference across at least one of the variables (education and normalized whole brain volume).*

```{R, warning=FALSE}
#compute observed F
SST<- sum(dists^2)/150
SSW<-dementia%>%group_by(Demented)%>%select(EDUC,nWBV)%>%
 do(d=dist(.[1:2],"euclidean"))%>%ungroup()%>%
 summarize(sum(d[[1]]^2)/50 + sum(d[[2]]^2)/50)%>%pull
F_obs<-((SST-SSW)/2)/(SSW/147) 
F_obs #observed F statistic
```

```{R, warning=FALSE}
#create null distribution

Fs<-replicate(1000,{
new<-dementia%>%mutate(Demented=sample(as.factor(Demented))) #permute the Demented vector
SSW<-new%>%group_by(Demented)%>%select(EDUC,nWBV)%>%
 do(d=dist(.[1:2],"euclidean"))%>%ungroup()%>%
 summarize(sum(d[[1]]^2)/50 + sum(d[[2]]^2)/50)%>%pull
((SST-SSW)/2)/(SSW/147) #calculate new F on randomized data
})
```

```{R}
#Histogram of null distribution
{hist(Fs,prob = T); abline(v=F_obs, col="red", add=T)}
```

```{R}
#Is it significantly different than an expected F value?
mean(Fs>F_obs) #0.007
```
##### *Results: Reject the null, there is a significant mean difference across at least one of the variables (education or normalized whole brain volume) (p = 0.007).*


## *Multiple Regression*

```{R}
#MULTIPLE REGRESSION
dementia2 <- dementia %>% mutate(EDUC_center = EDUC - mean(EDUC), Age_center = Age - mean(Age), nWBV_center = nWBV - mean(nWBV), Demented = as.factor(Demented)) #centering variables

fit<-lm(nWBV_center ~ Age_center * Demented, data=dementia2) #Creating fit for multiple regression

summary(fit) #Regression output
```
##### *In an individual of average age without dementia, centered normalized whole brain volume is 0.0104105 units. For individuals without dementia, centered normalized whole brain volume decreases by 0.0029189 units for every 1 unit increase age (centered). For individuals of average age with dementia, centered normalized whole brain volume decreases by 0.0236807 for every 1 unit increase in dementia (since the "Demented" variable only has 2 levels, this means that the presence of dementia corresponds to a centered normalized brain volume that is 0.0236807 units lower than it would be if the individual did not have dementia). For individuals of average age without dementia, centered normalized whole brain volume increases by 0.0005165 units for every 1 unit increase in the interaction between age and dementia status.*

```{R}
#REGRESSION PLOT
ggplot(dementia2, aes(x=Age_center, y=nWBV_center, group=Demented))+ geom_point(aes(color=Demented))+
 geom_smooth(method="lm",se=F,fullrange=T,aes(color=Demented))+
theme(legend.position=c(.9,.75))+xlab("Age (centered)") + ylab("Normalized Whole Brain Volume (centered)") +
  ggtitle("Prevelance of Dementia based on Age and Whole Brain Volume")
```

##### *The regression plot shows that normalized whole brain volume clearly decreases with age, and is lower in demented individuals than nondemented individuals.*

```{R}
#LINEARITY AND HOMOSKEDASTICITY ASSUMPTIONS
library(sandwich); library(lmtest) #loading some libraries

resids<-fit$residuals
fitvals<-fit$fitted.values
ggplot()+geom_point(aes(fitvals,resids))+geom_hline(yintercept=0, color='red') +
  ggtitle("Linearity and Homoskedasticity Examination")

bptest(fit) #testing heteroskedasticity assumption
```
##### *Null hypothesis of the Breusch-Pagan test is that the distribution is homoskedastic; fail to reject, so distribution is homoskedastic. Graphical distribution looks decent enough.*

```{R}
#NORMALITY ASSUMPTION
shapiro.test(resids) #Shapiro-Wilk normality test
```
##### *Null hypothesis: distribution is normal; fail to reject, so distribution is normal.*

```{R}
#Robust SEs
#install.packages("lmtest")
#install.packages("sandwich")
library(lmtest); library(sandwich) #need these packages
```

```{R}
#results with robust SEs:
coeftest(fit, vcov = vcovHC(fit))
```
##### *Results: Age and status of dementia both remained significant predictors of whole brain volume, while the interaction remained not significant. The significance of these variables and the interaction did not change before and after using robust standard errors. The robust standard errors are almost exactly the same as in the original regression.*

```{R}
#re-examining output of fit model to get the adjusted R squared
summary(fit)
```
##### *The adjusted R squared value for the model is 0.3913, indicating that the model explains 39.13% of the variance in whole brain volume.*

```{R}
#COMPARISON BETWEEN MODELS
fit1<-lm(nWBV_center ~ Age_center + Demented, data=dementia2)
anova(fit,fit1,test="LRT")
```
##### *Null hypothesis is that the simpler model is better; fail to reject, so the model containing only main effects is the best in this case.*

```{R}
#BOOTSTRAPPED SEs

#Sample rows from dataset with replacement
boot_dat<-dementia2[sample(nrow(dementia2),replace=TRUE),]
```

```{R}
# repeat 5000 times, saving the coefficients each time 
samp_distn<-replicate(5000, {  
  boot_dat<-dementia2[sample(nrow(dementia2),replace=TRUE),]
  fit<-lm(nWBV_center ~ Age_center * Demented, data=boot_dat)   
  coef(fit) 
  })
```

```{R}
#Estimated SEs
samp_distn%>%t%>%as.data.frame%>%summarize_all(sd)
```
##### *The boostrapped SEs are almost identical to the robust and original SEs; in fact, some are slightly lower than the robust SEs and the original SEs (but only VERY slightly; again, they are virtually all the same small values). The SEs for the original regression, robust SEs, and boostrapped SEs (respectively) are as follows: Intercept: 0.0034674, 0.00363754, 0.003526455; Age_center: 0.0004241, 0.00042445, 0.0004217431; Dementia status: 0.0052431, 0.00525207, 0.005134726; Interaction between age and dementia status: 0.0007003, 0.00066166, 0.0006728562. In cases where the SE increased between the original/robust/bootstrapped SEs, the p value increased and the t value decreased. In cases where SE decreased between the original/robust/boostrapped SEs, the p value decreased and the t value increased. Since the changes in SEs were so small between these adjustments, the significance of the variables/interaction did not change.*


## *Logistic Regression*

```{R}
#class_diag code
class_diag<-function(probs,truth){
  
  tab<-table(factor(probs>.5,levels=c("FALSE","TRUE")),truth)
  acc=sum(diag(tab))/sum(tab)
  sens=tab[2,2]/colSums(tab)[2]
  spec=tab[1,1]/colSums(tab)[1]
  ppv=tab[2,2]/rowSums(tab)[2]

  if(is.numeric(truth)==FALSE & is.logical(truth)==FALSE) truth<-as.numeric(truth)-1
  
  #CALCULATE EXACT AUC
  ord<-order(probs, decreasing=TRUE)
  probs <- probs[ord]; truth <- truth[ord]
  
  TPR=cumsum(truth)/max(1,sum(truth)) 
  FPR=cumsum(!truth)/max(1,sum(!truth))
  
  dup<-c(probs[-1]>=probs[-length(probs)], FALSE)
  TPR<-c(0,TPR[!dup],1); FPR<-c(0,FPR[!dup],1)
  
  n <- length(TPR)
  auc<- sum( ((TPR[-1]+TPR[-n])/2) * (FPR[-1]-FPR[-n]) )

  data.frame(acc,sens,spec,ppv,auc)
}
```

```{R}
#LOGISTIC REGRESSION

#creating a fit for the logistic regression
fit <- glm(Demented~as.factor(M.F) + Age + EDUC + SES + scale(nWBV), data = dementia, family = "binomial")
coeftest(fit) #output of logistic regression model
```
##### *These variables were chosen because they appear to be the most meaningful in the dataset; other variables were excluded for being non-informative or for being adjacent tests that predict dementia (I didn't want to include predictions in my model designed to predict dementia).*

```{R}
exp(0.866775) #exponentiate coefficient for gender 
exp(-0.079016) #exponentiate coefficient for age
exp(-0.2108951) #exponentiate coefficient for years of education 
exp(-0.087040) #exponentiate coefficient for socioeconomic status
exp(-0.934636) #exponentiate coefficient for normalized whole brain volume
```
##### *Gender, age, years of education, and whole brain volume significantly increase the log odds of having dementia (make it more likely). Being a male increases the odds of dementia by 237.9% compared to females. For ever one unit increase in age, the odds of having dementia decrease by about 7.6%. For every one unit increase in years of education, the odds of dementia decrease by 19.1% (they change by a factor of .809). For every one unit increase in SES, the odds of dementia decrease by about 8.4% (not significant). Going up one standard deviation in normalized whole brain volume decreases odds of dementia by about 60%.*

```{R}
prob <- predict(fit, type = "response") #creating a vector of probabilities of dementia based on the model fit

#CONFUSION MATRIX
table(predict = as.numeric(prob>0.5), truth = dementia$Demented) %>% addmargins
```
##### *Model does decently according to the confusion matrix.*

```{R}
#CLASSIFICATION DIAGNOSTICS
class_diag(prob, dementia$Demented)
```
##### *The accuracy for this model is 0.65625, the sensitivity is 0.4642857, and the specificity is 0.8055556. So, the model will correctly identify patients who either do or do not have dementia 65.6% of the time, while predicting true positives (patients who have dementia) 46.4% of the time and true negatives (patients who do not have dementia) 80.6% of the time. The ppv is 0.65, indicating that the model predicts positives that are actually positives 65% of the time. In this case, out of 40 predicted positives, 26 were true positives (equating to 65%).*

```{R}
#DENSITY PLOT OF LOGIT
dementia1 <- dementia
dementia1$logit <- predict(fit, type = "link")

dementia1 %>% ggplot(aes(logit,fill = as.factor(Demented)))+geom_density(alpha = 0.4) +
  geom_vline(xintercept=0)+theme(legend.position=c(.9,.9))+
  labs(fill='Demented') +
  ggtitle("Logit Density Plot")
```

##### *The density plot shows that the model is more accurate than pure guesswork, but there is still a fairly high amount of false positives and false negatives as indicated by the overlapping regions.*

```{R}
#ROC PLOT
#install.packages("plotROC")
library(plotROC) 

ROCplot<-ggplot(dementia)+geom_roc(aes(d=Demented,m=prob), n.cuts=0)+
 geom_segment(aes(x=0,xend=1,y=0,yend=1),lty=2) +
  xlab("FPR") +
  ylab("TPR") +
  ggtitle("ROC Curve")
ROCplot
```

##### *The resulting plot shows that the current model is performing above what would be random guessing of dementia status.*

```{R}
#10-fold CV
set.seed(1234)
k=10

data1<-dementia[sample(nrow(dementia)),]
folds<-cut(seq(1:nrow(dementia)),breaks=k,labels=F)

diags<-NULL
for(i in 1:k){
  train<-data1[folds!=i,]
  test<-data1[folds==i,]
  truth<-test$Demented
  
  fit<-glm(Demented~M.F + Age + EDUC + SES + eTIV, data=train, family = "binomial")
  probs<-predict(fit,newdata = test, type="response")

diags<-rbind(diags,class_diag(probs,truth))
}

diags%>%summarize_all(mean)
```
##### *The average out-of-sample classification diagnostics are as follows: accuracy is 0.6173077, sensitivity is 0.4021429, specificity is 0.7657937, and ppv is 0.6316667. These are all slightly lower than the corresponsing classification diagnostics for the entire dataset, indicating that the model is very slightly overfitting.*


## *LASSO*

```{R}
#LASSO
#install.packages("glmnet")
library(glmnet)
```
##### *Again, some of the variables are themselves predictions of dementia; not including them, since I am trying to predict dementia based on variables that are not dementia predictions. I included a few other variables that I know do not predict dementia, just to show that the lasso parses them out from the variables that actually matter.*
```{R}
#creating a fit that has a bunch of variables from the dataset
fit <- glm(Demented~M.F + Age + EDUC + SES + eTIV + nWBV + ASF, data = dementia, family = "binomial")
coeftest(fit)
```
##### *It seems like only some of these are significant and ought to be included in the final logistic regression.*

```{R}
y <- as.matrix(dementia$Demented) #truth values
x<-model.matrix(fit) %>% as.data.frame %>% dplyr::select(-`(Intercept)`) %>% as.matrix()
cv<-cv.glmnet(x,y)

lasso1 <- glmnet(x, y, lambda = cv$lambda.1se)
coef(lasso1) 
```
##### *This changes very slightly every time, but the variables I get most often are gender, education, and normalized whole brain volume. These should be the strongest predictors of dimentia status.*

```{R}
#creating a new fit with only the lasso variables
fit1 <- glm(Demented~M.F + EDUC + nWBV, data = dementia, family = "binomial") 

prob1 <- predict(fit1, type = "response") #generating a vector of probabilities

class_diag(prob1, dementia$Demented) #classification diagnostics
```

```{R}
#confusion matrix using only lasso variables
table(predict=as.numeric(prob1>.5),truth=dementia$Demented)%>%addmargins
```
##### *Does pretty well!*

```{R}
#10-fold CV on LASSO regression:
set.seed(1234)
k=10

data1<-dementia[sample(nrow(dementia)),] #put dataset in random order
folds<-cut(seq(1:nrow(dementia)),breaks=k,labels=F) #create folds

diags<-NULL
for(i in 1:k){ # FOR EACH OF 10 FOLDS
  train<-data1[folds!=i,] #CREATE TRAINING SET
  test<-data1[folds==i,] #CREATE TESTING SET
  truth<-test$Demented
  
  fit<- glm(Demented~M.F + EDUC + nWBV, data = train, family="binomial")
  probs<- predict(fit1,newdata = test,type="response")
  
  diags<-rbind(diags,class_diag(probs,truth)) 
}

apply(diags,2,mean)
```
##### *Out-of-sample accuracy for the lasso regression is 0.6474359, while the out-of-sample accuracy for the original logistic regression was 0.6173077. These values are fairly close, with the lasso regression having the added advantage of containing fewer predictor variables (3 instead of 5) and performing slightly better. The lasso regression also has a slightly higher out-of-sample AUC of 0.7415476, compared to an out-of-sample AUC of 0.6632639 in the original logistic regression. The out-of-sample classification diagnostics for the lasso regression are slightly higher than the corresponding classification diagnostics for the entire dataset, indicating that the lasso regression is a better model for predicting dementia status using out-of-sample data.*

```{R}
#ROC plot using only LASSO variables:
ROCplot1<-ggplot(dementia)+geom_roc(aes(d=Demented,m=prob1), n.cuts=0)+
 geom_segment(aes(x=0,xend=1,y=0,yend=1),lty=2) +
  xlab("FPR") +
  ylab("TPR") +
  ggtitle("ROC Curve for LASSO Fit")
ROCplot1
```

##### *This ROC curve is slightly better than the previous one.*
